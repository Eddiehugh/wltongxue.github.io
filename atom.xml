<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>wltongxue</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-01-06T12:45:49.997Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>wltongxue</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据挖掘实战2-航空公司客户价值分析</title>
    <link href="http://yoursite.com/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%982-%E8%88%AA%E7%A9%BA%E5%85%AC%E5%8F%B8%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/数据挖掘实战2-航空公司客户价值分析/</id>
    <published>2019-01-05T09:07:38.000Z</published>
    <updated>2019-01-06T12:45:49.997Z</updated>
    
    <content type="html"><![CDATA[<p>本次学习我们仍然遵循“什么是数据挖掘”文章中的研究方法对航空公司消费客户进行聚类。本章学习重点是如何标准化处理数据，使用k-means聚类，明白聚类和分类的区别。<br><a id="more"></a></p><blockquote><p>问题背景：假设你是航空公司的，如何针对不同的顾客进行活动的推销，维持经常飞行的顾客，吸引新的顾客。这就需要我们对顾客进行聚类，那么什么是聚类，为什么不叫分类。因为分类是有监督的学习，聚类是无监督的学习。我们可以对比实战1，可以发现在实战1中我们的数据里明确是有分类的结果供模型去学习的（两个分类结果，一个是偷电用户，一个是非偷电用户），但是本章学习中我们并不清楚我们都有哪几类用户，要把数据分为哪几类。所以一个是分类，一个是聚类。</p></blockquote><h1 id="一、挖掘目标"><a href="#一、挖掘目标" class="headerlink" title="一、挖掘目标"></a>一、挖掘目标</h1><p>1、借助航空公司客户数据，对客户进行聚类<br>2、对不同的客户类别进行特征分析，比较不同类别的客户价值</p><h1 id="二、数据抽取"><a href="#二、数据抽取" class="headerlink" title="二、数据抽取"></a>二、数据抽取</h1><p>1、客户个人信息，包括会员卡号、入会时间、性别、年龄等<br>2、客户乘机记录，包括，飞行次数、飞行时间、乘机间隔、平均折扣等<br>如图是实际采集的数据：<br><img src="/数据挖掘实战2-航空公司客户价值分析/metadata.png" width="800" height="800"><br>属性值意义参考表：<br><img src="/数据挖掘实战2-航空公司客户价值分析/attribute_means.png" width="800" height="800"></p><h1 id="三、数据探索：统计分析"><a href="#三、数据探索：统计分析" class="headerlink" title="三、数据探索：统计分析"></a>三、数据探索：统计分析</h1><p>1、对数据进行缺失值分析与异常值分析<br>2、查找每列属性的空值个数、最大值、最小值<br>使用python进行数据的统计，源码如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#对数据进行基本的探索</span></span><br><span class="line"><span class="comment">#返回缺失值个数以及最大最小值</span></span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">datafile=<span class="string">'../data/air_data.csv'</span> <span class="comment">#航空原始数据，第一行为属性标签</span></span><br><span class="line">result_file=<span class="string">'../tmp/explore.xls'</span><span class="comment">#数据探索结果表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#读取原始数据，指定UTF-8编码（需要用文本编辑器将数据转换为UTF-8编码）</span></span><br><span class="line">data=pd.read_csv(datafile,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment">#包括对数据的基本描述，</span></span><br><span class="line"><span class="comment">#percentiles参数是指定计算多少的分位数表（如1/4分位数，中位数等）;</span></span><br><span class="line"><span class="comment">#T是转置，转置后更方便查阅</span></span><br><span class="line">explore=data.describe(percentiles= [],include=<span class="string">'all'</span>).T</span><br><span class="line"><span class="comment">#describe()函数自动计算非空值数，需要手动计算空值数</span></span><br><span class="line">explore[<span class="string">'null'</span>]=len(data)-explore[<span class="string">'count'</span>]</span><br><span class="line"></span><br><span class="line">explore=explore[[<span class="string">'null'</span>,<span class="string">'max'</span>,<span class="string">'min'</span>]]</span><br><span class="line">explore.columns = [u<span class="string">'空值表'</span>,u<span class="string">'最大值'</span>,u<span class="string">'最小值'</span>]<span class="comment">#表头重命名</span></span><br><span class="line"><span class="string">''</span><span class="string">'这里只选取部分探索结果。</span></span><br><span class="line"><span class="string">dscribe()函数自动计算的字段有count(非空值表),unique(唯一值数),top(频数最高者),</span></span><br><span class="line"><span class="string">    freq(最高频数)、mean(平均值),std(方差),min(最小值),50%(中位数),max(最大值)'</span><span class="string">''</span></span><br><span class="line">explore.to_excel(result_file)<span class="comment">#导出结果</span></span><br><span class="line">``` </span><br><span class="line">统计结果如下:</span><br><span class="line">&lt;img src=<span class="string">"explore.png"</span> width=800 height=800 /&gt;</span><br><span class="line"><span class="comment"># 四、数据预处理</span></span><br><span class="line"><span class="comment">## 1、数据清洗</span></span><br><span class="line">1、丢弃票价为空的记录</span><br><span class="line">2、丢弃票价为0，但平均折扣率不为0，总飞行公里数大于0的记录。（脏数据）</span><br><span class="line">python进行如上数据清洗:</span><br><span class="line">```bash</span><br><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#数据清洗，过滤掉不符合规则的数据</span></span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">datafile=<span class="string">'../data/air_data.csv'</span><span class="comment">#航空原始数据，第一行为属性标签</span></span><br><span class="line">cleanedfile=<span class="string">'../tmp/data_cleanedxls'</span><span class="comment">#数据清洗后保存的文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#读取原始数据,指定UTF-8编码（需要用文本编辑器将数据转换为UTF-8编码）</span></span><br><span class="line">data=pd.read_csv(datafile,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">data=data[data[<span class="string">'SUM_YR_1'</span>].notnull()&amp;data[<span class="string">'SUM_YR_2'</span>].notnull()]<span class="comment">#票价非空值才保留</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#只保留票价非零的，或者 平均折扣率与总飞行数为0的记录</span></span><br><span class="line"><span class="comment">#若票价为0，则折扣和飞行数也应为0，这样的记录也保留</span></span><br><span class="line">index1=data[<span class="string">'SUM_YR_1'</span>]!=0</span><br><span class="line">index2=data[<span class="string">'SUM_YR_2'</span>]!=0</span><br><span class="line">index3=(data[<span class="string">'SEG_KM_SUM'</span>]==0)&amp;(data[<span class="string">'avg_discount'</span>]==0)<span class="comment">#该规则是与</span></span><br><span class="line">data=data[index1|index2] <span class="comment">#该规则是或</span></span><br><span class="line"></span><br><span class="line">data.to_excel(cleanedfile)<span class="comment">#导出结果</span></span><br></pre></td></tr></table></figure></p><h2 id="2、数据规约"><a href="#2、数据规约" class="headerlink" title="2、数据规约"></a>2、数据规约</h2><p>原始数据属性太多，我们使用LRFMC模型，选择6个与LRFMC模型相关属性指标，以供接下来构造LRFMC模型。如下图所示：<br> <img src="/数据挖掘实战2-航空公司客户价值分析/LRFMC.png" width="800" height="800"></p><h2 id="3、数据变换"><a href="#3、数据变换" class="headerlink" title="3、数据变换"></a>3、数据变换</h2><ul><li>1、构建LRFMC这五个指标如下公式（都在观测窗口(某个约定的时间段)内进行计算）:<br>（1）会员入会时间：L=LOAD_TIME-FPP_DATE<br>（2）最后一次乘车时间到结束的月数：R=LAST_TO_END<br>（3）飞行次数：F=FLIGHT_COUNT<br>（4）总飞行公里数：M=SEG_KM_SUM<br>（5）平均折扣率C=AVG_DISCOUNT</li><li>2、由数据探索时候，统计可知，这5个指标实际上取值范围相差较大。我们一般为了消除数量级数据带来的影响，需要对数据进行标准化处理(详情请<a href="https://wltongxue.github.io/updating/" target="_blank" rel="noopener">点击这里</a>)。<br>python实现数据标准化：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#标准差标准化</span></span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">datafile=<span class="string">'../data/zscoredata.xls'</span><span class="comment">#需要进行标准化的数据文件</span></span><br><span class="line">zscoredfile=<span class="string">'../tmp/zscoreddata.xls'</span><span class="comment">#标准差化后的数据存储路径文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#标准化处理</span></span><br><span class="line">data=pd.read_excel(datafile)</span><br><span class="line"><span class="comment">#简洁的语句实现了标准化变换，</span></span><br><span class="line"><span class="comment">#类似地可以实现任何想要的变换</span></span><br><span class="line">data=(data-data.mean(axis=0))/(data.std(axis=0))</span><br><span class="line"></span><br><span class="line">data.columns=[<span class="string">'Z'</span>+i <span class="keyword">for</span> i <span class="keyword">in</span> data.columns] <span class="comment">#表头重命名</span></span><br><span class="line"></span><br><span class="line">data.to_excel(zscoredfile,index=False)<span class="comment">#数据写入</span></span><br></pre></td></tr></table></figure></li></ul><p>由上面两步，一个属性规约，一个数据标准化后，得到的数据如下图所示：<br> <img src="/数据挖掘实战2-航空公司客户价值分析/zscore_data.png" width="800" height="800"></p><h1 id="五、模型构建"><a href="#五、模型构建" class="headerlink" title="五、模型构建"></a>五、模型构建</h1><p>到此为止，我们已经获取到相对适合处理的干净数据了，本步我们选用k-means聚类算法(详情<a href="https://wltongxue.github.io/updating/" target="_blank" rel="noopener">请点击这里</a>)进行聚类。实际上聚类完成后我们会获取到每一类的中心，这个时候我们可以把它保存下来，可以用来分类未知的增量数据。<br>我们进行聚类的整体过程如下图，用历史数据进行K-means聚类获得聚类的中心点，然后再用增量数据在中心点上进行分类，这里简单提一下。聚类实际上用的就是距离相近的属于一类。<br><img src="/数据挖掘实战2-航空公司客户价值分析/process.png" width="800" height="800"><br>按照上面的步骤我们对数据进行python聚类：<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line">import sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'ISO-8859-1'</span>)</span><br><span class="line"><span class="comment">#K-means聚类算法</span></span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.cluster import KMeans <span class="comment">#导入K均值聚类算法（欧式距离）</span></span><br><span class="line"></span><br><span class="line">inputfile=<span class="string">'../tmp/zscoreddata.xls'</span><span class="comment">#待聚类的数据文件</span></span><br><span class="line">outputfile=<span class="string">'../tmp/kmeans_result.xls'</span></span><br><span class="line"></span><br><span class="line">k=5 <span class="comment">#需要进行的聚类类别数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据并进行聚类分析</span></span><br><span class="line">data=pd.read_excel(inputfile)<span class="comment">#读取数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#调用K-means算法，进行聚类分析</span></span><br><span class="line">kmodel=KMeans(n_clusters=k,n_jobs=4)<span class="comment">#n_jobs是并行数，一般等于CPU数比较好</span></span><br><span class="line">kmodel.fit(data)<span class="comment">#训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#详细输出客户聚类结果</span></span><br><span class="line">r1=pd.Series(kmodel.labels_).value_counts() <span class="comment">#统计各个类别的数目</span></span><br><span class="line">r2=pd.DataFrame(kmodel.cluster_centers_)<span class="comment">#找出聚类中心</span></span><br><span class="line">r=pd.concat([r2,r1],axis=1) <span class="comment">#横向连接（0是纵向），得到聚类中心对应的类别下的数目</span></span><br><span class="line">r.columns=list(data.columns)+[u<span class="string">'类别数目'</span>] <span class="comment">#重命名表头</span></span><br><span class="line">r.to_excel(outputfile)<span class="comment">#保存结果</span></span><br></pre></td></tr></table></figure></p><p>我们这里设置聚类的数量为5类，然后会得到每一个属性每一类的聚类中心值，如下图：<br><img src="/数据挖掘实战2-航空公司客户价值分析/k-means_result.png" width="800" height="800"></p><h1 id="六、特征分析"><a href="#六、特征分析" class="headerlink" title="六、特征分析"></a>六、特征分析</h1><p>为了便于可视化分析，我们使用python将结果绘制成雷达图(接上面的代码)：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#绘制雷达图</span></span><br><span class="line">import matplotlib.pyplot as plt <span class="comment">#包含画图工具</span></span><br><span class="line">import numpy as np</span><br><span class="line"><span class="comment">#设置ggplot的绘画风格</span></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>]=<span class="string">'simkai'</span><span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = False <span class="comment">#用来正常显示负号</span></span><br><span class="line"><span class="comment">#标签</span></span><br><span class="line">labels=np.array(data.columns)</span><br><span class="line"><span class="comment">#数据个数</span></span><br><span class="line">dataLenth=5</span><br><span class="line">N=len(r2)</span><br><span class="line">angles=np.linspace(0,2*np.pi,N,endpoint=False)</span><br><span class="line">data=pd.concat([r2,r2.ix[:,0]],axis=1)</span><br><span class="line">angles=np.concatenate((angles,[angles[0]]))<span class="comment">#使雷达图一圈封闭起来</span></span><br><span class="line"></span><br><span class="line">fig=plt.figure(figsize=(6,6))</span><br><span class="line">ax=fig.add_subplot(111,polar=True)<span class="comment">#这里一定要设置为极坐标格式</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(0,5):</span><br><span class="line">    j=i+1</span><br><span class="line">    ax.plot(angles,data.ix[i,:],<span class="string">'o-'</span>,linewidth=2,label=<span class="string">"Customers&#123;0&#125;"</span>.format(j))<span class="comment">#画线</span></span><br><span class="line"></span><br><span class="line">ax.set_thetagrids(angles *180/np.pi,labels)<span class="comment">#添加每个特征的标签</span></span><br><span class="line">ax.set_title(<span class="string">"Customers Analysis"</span>,va=<span class="string">'bottom'</span>,fontproperties=<span class="string">"SimHei"</span>)<span class="comment">#添加标题</span></span><br><span class="line">ax.set_rlim(-1,2.5)<span class="comment">#设置雷达图范围</span></span><br><span class="line">ax.grid(True)<span class="comment">#添加网格</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p>雷达图如下：<br><img src="/数据挖掘实战2-航空公司客户价值分析/analysis.png" width="800" height="800"><br>根据特征描述表，定义5种客户：<br>1、重要保持客户：<br>    平均折扣率(C)较高，最近乘坐航班时间(R)低，乘坐次数(M)或者里程(M)较高<br>2、重要发展客户：<br>    平均折扣率(C)较高，最近乘坐航班时间(R)低，但入会时间(L)短，乘坐次数(F)或乘坐里程(M较低)<br>3、重要挽留客户：<br>    过去平均折扣率(C)较高，乘坐次数(F)或里程(M)较高，但长时间没有乘坐(R)<br>4、一般与低价值客户<br>    平均折扣率(C)较低，较长时间没有乘坐本航班(R)，乘坐次数h(F)或里程(M)较低，入会时间短(L)<br><img src="/数据挖掘实战2-航空公司客户价值分析/class_result.png" width="800" height="800"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次学习我们仍然遵循“什么是数据挖掘”文章中的研究方法对航空公司消费客户进行聚类。本章学习重点是如何标准化处理数据，使用k-means聚类，明白聚类和分类的区别。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="数据挖掘实战讲解系列" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%E8%AE%B2%E8%A7%A3%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="聚类问题" scheme="http://yoursite.com/tags/%E8%81%9A%E7%B1%BB%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>ROC曲线</title>
    <link href="http://yoursite.com/ROC/"/>
    <id>http://yoursite.com/ROC/</id>
    <published>2019-01-03T12:23:01.000Z</published>
    <updated>2019-01-03T12:49:44.524Z</updated>
    
    <content type="html"><![CDATA[<p>本次学习我们将看看当一个机器算法模型训练完成后，如何使用ROC曲线来衡量它的好坏。会介绍混淆矩阵、ROC曲线如何生成。<br><a id="more"></a></p><h1 id="一、混淆矩阵"><a href="#一、混淆矩阵" class="headerlink" title="一、混淆矩阵"></a>一、混淆矩阵</h1><p>对于二分类来说，混淆矩阵就分为四个模块：<br>结果为“真”的分对了就是True Positives；<br>结果为“真”的分错了就是False Positives；<br>结果为“假”的分对了就是True Negatives；<br>结果为“假”的分错了就是False Negatives；<br>这个还是比较容易混乱，大家就记住“True”就代表分队了，“False”就代表分错了.如下图所示，我们还能够获得fp rate、tp rate、precision、recall、accuracy、F-measure的计算过程：<br><img src="/ROC/Confusion_matrix.png" width="800" height="800"></p><h1 id="二、ROC曲线图"><a href="#二、ROC曲线图" class="headerlink" title="二、ROC曲线图"></a>二、ROC曲线图</h1><h2 id="1、理解ROC"><a href="#1、理解ROC" class="headerlink" title="1、理解ROC"></a>1、理解ROC</h2><p>于是，由于：$FPrate=\frac{FP}{FP+TN}$，$TPrate=\frac{TP}{TP+FN}$，可画出下面的ROC曲线图：<br><img src="/ROC/roc.png" width="400" height="400"><br>接下来我们来解释一下这个图：</p><p><1>第一个点(0,1)，即FP_rate=0,TP_rate=1,这意味着FN（false negative）=0,并且FP（false positive）=0。这是一个完美的分类器，它将所有的样本都正确分类。</1></p><p><2>第二个点(1,0)，即FP_rate=1,TP_rate=0,类似地分析可以发现这是一个最糟糕的分类器，因为它成功的避开了所有正确答案。</2></p><p><3>第三个点(0,0)，即FP_rate=TP_rate=0，即FP（false positive）=TP（true positive）=0，可以发现该分类器预测所有的样本都为负样本（negative）</3></p><p><4>第四个点(1,1)，分类器预测所有的样本都为正样本。<br>经以上分析，可以发现，ROC曲线越接近左上角，该分类器的性能越好。</4></p><blockquote><p>问题：对于一个特定的分类器和测试数据集，显然只能得到一个分类混淆矩阵，即ROC线上的一个点，若要一系列的点怎么办？</p></blockquote><h2 id="2、绘制ROC"><a href="#2、绘制ROC" class="headerlink" title="2、绘制ROC"></a>2、绘制ROC</h2><p>举个例子<br><img src="/ROC/classification.png" width="400" height="400"><br>接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。<br><strong>每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值</strong><br>画出ROC图：<br><img src="/ROC/roc_paint.png" width="600" height="600"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次学习我们将看看当一个机器算法模型训练完成后，如何使用ROC曲线来衡量它的好坏。会介绍混淆矩阵、ROC曲线如何生成。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习算法" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="算法评估" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0/"/>
    
  </entry>
  
  <entry>
    <title>LM_BP神经网络算法详解</title>
    <link href="http://yoursite.com/LM-BP/"/>
    <id>http://yoursite.com/LM-BP/</id>
    <published>2019-01-03T11:37:33.000Z</published>
    <updated>2019-01-03T12:25:35.985Z</updated>
    
    <content type="html"><![CDATA[<p>本次学习我们将介绍BP前向神经网络算法以及从BP延申的LM神经网络算法。了解神经网络算法的概念，算法原理。<br><a id="more"></a></p><h1 id="一、BP神经网络算法"><a href="#一、BP神经网络算法" class="headerlink" title="一、BP神经网络算法"></a>一、BP神经网络算法</h1><h2 id="1、概念"><a href="#1、概念" class="headerlink" title="1、概念"></a>1、概念</h2><p>神经网络算法实际上是一种叠加的算法，对于每一个神经元来说，对输入信号$X=[x_1,x_2,…,x_m]^T$的输出$y$为$Y=f(u+b)$，其中$u=\sum_{i=1}^m{w_ix_i}$，如图所示：<br><img src="/LM-BP/single_neutral.png" width="350" height="350"><br>这里说到激活函数，我们可以看看激活函数的种类：<br><img src="/LM-BP/activation_func.png" width="800" height="800"><br>信号每经过一个神经元就会进行模型的运算，再将结果输出给下一个神经元，一层接一层就构成了神经网络，这里展示一个三层BP的神经网络结构。<br>我们可以举个例子，比如你是否喜欢喝酒是$x_1$，你是否喜欢蹦迪是$x_2$，你是否喜欢睡觉是$x_3$，输入之后在第二层每个神经元就结合这三个元素计算了起来，最后会输出$y$代表你会不会喜欢去夜店，如果我们有一万个不同的人回答这个问题，用8000个人的回答训练这个模型，最后模型会判断剩下2000人到底会不会喜欢去夜店。当然这是一种输出，神经元也可以有多种输出。<br><strong>注意，信号是正向传播的，但误差逆向传播，因为在神经元的训练过程中，每一个神经元学习的时候会根据误差调整自己以及之前的模型参数</strong><br><img src="/LM-BP/three_bp.png" width="350" height="350"></p><h2 id="2、算法过程"><a href="#2、算法过程" class="headerlink" title="2、算法过程"></a>2、算法过程</h2><p>这个算法图清晰的说明了信号正向传播训练，误差逆向修正权值。这里的学习率，误差越小，学习率也会下降，误差越大，学习率也会增大，这样是为了更快的逼近好的权值。<br><img src="/LM-BP/bp_process.png" width="800" height="800"><br>综上可以看出，基于梯度下降算法（初始阶段优化）和牛顿法（收敛快）结合的多层前馈网络，特点：迭代次数少，收敛速度快，精度高<br>LM对初值（权值、阈值）较为依赖，是BP算法的改进版，接下来我们看看LM算法改进在了哪里</p><h1 id="二、LM神经网络算法"><a href="#二、LM神经网络算法" class="headerlink" title="二、LM神经网络算法"></a>二、LM神经网络算法</h1><h2 id="1、改进之处"><a href="#1、改进之处" class="headerlink" title="1、改进之处"></a>1、改进之处</h2><p><img src="/LM-BP/lm1.png" width="800" height="800"><br><img src="/LM-BP/lm2.png" width="800" height="800"><br><img src="/LM-BP/lm3.png" width="800" height="800"></p><h2 id="2、算法过程-1"><a href="#2、算法过程-1" class="headerlink" title="2、算法过程"></a>2、算法过程</h2><p><img src="/LM-BP/lm_process.png" width="800" height="800"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次学习我们将介绍BP前向神经网络算法以及从BP延申的LM神经网络算法。了解神经网络算法的概念，算法原理。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习算法" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="http://yoursite.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>ID3、CART算法</title>
    <link href="http://yoursite.com/CART/"/>
    <id>http://yoursite.com/CART/</id>
    <published>2019-01-02T11:06:52.000Z</published>
    <updated>2019-01-03T12:25:43.781Z</updated>
    
    <content type="html"><![CDATA[<p>本次学习我们将详细介绍什么是CART决策树算法，以及它的前身ID3算法。介绍所涉及到的概念，算法的原理和步骤。<br><a id="more"></a></p><h1 id="一、介绍ID3算法"><a href="#一、介绍ID3算法" class="headerlink" title="一、介绍ID3算法"></a>一、介绍ID3算法</h1><h2 id="1、概念"><a href="#1、概念" class="headerlink" title="1、概念"></a>1、概念</h2><h3 id="信息熵："><a href="#信息熵：" class="headerlink" title="信息熵："></a>信息熵：</h3><p>用来度量一个属性的信息量。<br>假定S为训练集，S的目标属性C具有m个可能的类标号值，$C={C_1,C_2,…,C_m}$，假定训练集S中，$C_i$在所有样本中出现的频率为$P_i(i=1,2,3,…,m)$，则该训练集S所包含的信息熵定义为：<br>$$Entropy(S = Entropy(p_i,p_2,…,p_m) = -{\sum_{i=1}^m}{p_ilog_2p_i}$$<br>熵越小表示样本对目标属性的分布越纯，反之熵越大表示样本对目标属性分布越混乱。</p><h3 id="信息增益："><a href="#信息增益：" class="headerlink" title="信息增益："></a>信息增益：</h3><p>信息增益是划分前呀根本数据的熵和划分后样本数据集的熵的差值<br>假设划分前样本数据集为S，并用属性A来划分样本集S，则按属性A划分S的信息增益$Gain(S,A)$为样本集S的熵减去按属性A划分S后的样本自己的熵：<br>$$Gain(S,A)=Entropy(S)-Entropy_A(S)$$<br>按属性A划分S后的样本自己的熵定义如下：假定属性A有k个不同的取值，从而将S划分为k个样本子集${S_1,S_2,…,S_k}$，则按属性A划分S后的样本子集的信息熵为：<br>$$Entropy_A(S)={\sum_{i=1}^k}\frac{|S_i|}{|S|}Entropy(S_i)$$<br>其中$|S_i|(i=1,2,…,k)$为样本子集$S_i$中包含的样本数，$|S|$为样本集S中包含的样本数。信息增益越大，说明使用属性A划分后的样本子集越纯，越有利于分类。</p><blockquote><p>问题：用哪个属性最适合充当根节点？答：选择信息增益最大的。</p></blockquote><h2 id="2、ID3算法步骤"><a href="#2、ID3算法步骤" class="headerlink" title="2、ID3算法步骤"></a>2、ID3算法步骤</h2><p>ID3算法的具体详细实现步骤如下。<br>1）对当前样本集合，计算所有属性的信息增益；<br>2）选择信息增益最大的属性作为测试属性，把测试属性取值相同的样本划为同一个子样本集；<br>3）若子样本集的类别属性只含有单个属性，则分支为叶子节点，判断其属性值并标上相应的符号，然后返回调用处；否则对子样本集递归调用本算法。<br>其核心是在决策树的各级节点上，使用信息增益方法作为属性的选择标准，来帮助确定生成每个节点时所应采用的合适属性。即选择合适的属性节点及其顺序来构建决策树。</p><h1 id="二、CART决策树"><a href="#二、CART决策树" class="headerlink" title="二、CART决策树"></a>二、CART决策树</h1><h2 id="1、理解"><a href="#1、理解" class="headerlink" title="1、理解"></a>1、理解</h2><p>它既是回归树，又是分类树，但它是二叉树。ID3只能分类。<br>CART算法是一种二分递归分割技术，把当前样本划分为两个子样本，使得生成的每个非叶子节点都有两个分支，因此CART算法生成的决策树是结构简洁的二叉树。由于CART算法构成的是一个二叉树，它在每一步的决策时只能选择“是”或者“否”，即使一个feature有多个取值，也就是把数据分为两部分。在CART算法中主要分为两个步骤：<br>（1）将样本递归划分进行建树的过程<br>（2）用验证数据进行剪枝</p><h2 id="2、建树原理"><a href="#2、建树原理" class="headerlink" title="2、建树原理"></a>2、建树原理</h2><h3 id="1、如何进行划分"><a href="#1、如何进行划分" class="headerlink" title="1、如何进行划分"></a>1、如何进行划分</h3><p>属性是按照顺序一层层，着重划分属性值，注意，这里选的是属性值，而不是选属性。<br>设$x_1,x_2,…x_n$代表单个样本的$n$个属性，$y$表示所属类别。CART算法通过递归的方式将n维的空间划分为不重叠的矩形，划分步骤大致如下：<br>（1）选一个自变量$x_i$，再选取$x_i$的一个值$v_i$，$v_i$把$n$维空间划分为两部分，一部分的所有点都满足$x_i{\leq}v_i$，另一部分的所有点满足$x_i&gt;v_i$，对非连续变量来说属性值的取值只有两个，即等于该值或不等于该值。<br>（2）递归处理，将上面得到的两部分按照步骤（1）重新选取一个属性继续划分，知道把整个$n$维空间都划分完。</p><h3 id="2、按照什么标准来划分？"><a href="#2、按照什么标准来划分？" class="headerlink" title="2、按照什么标准来划分？"></a>2、按照什么标准来划分？</h3><p>每个属性的划分按照能减少的杂质的量来进行排序，而杂质的减少量定义为划分前的杂质减去划分后的每个节点的杂质量划分所占比率之和。而杂质度量方法常用$Gini指标$，假设一个样本Y共有C类，那么一个节点A（属性的某个确定值）的Gini不纯度可定义为：<br>$$Gini(A)=1-\sum_{i=1}^C{p_i^2}$$<br>其中$p_i$表示属于$i$类的概率，当$Gini(A=0$时，所有样本属于同类；<br>所有类在节点中以等概率出现时，$Gini(A)$最大化，此时等于$\frac{C(C-1)}{2}$。<br><strong>我们选最小的Gini作为节点</strong><br>$$Gini(M)=\frac{|A|}{|Y|}Gini(A)+\frac{|B|}{|Y|}Gini(B)$$<br>其中，Y表示样本总数，A，B是属性M的两个值</p><h2 id="3、剪枝"><a href="#3、剪枝" class="headerlink" title="3、剪枝"></a>3、剪枝</h2><h3 id="1、为什么要剪枝"><a href="#1、为什么要剪枝" class="headerlink" title="1、为什么要剪枝"></a>1、为什么要剪枝</h3><p>原因是避免决策树过拟合（Overfitting）样本。前面的算法生成的决策树非常详细并且庞大，每个属性都被详细地加以考虑，决策树的叶子节点所覆盖的训练样本都是“纯”的。因此用这个决策树来对训练样本进行分类的话，你会发现对于训练样本而言，这个树表现很好，误差率极低且能够正确的对训练样本集中的样本进行分类。训练样本中的错误数据也会被决策树学习，成为决策树的部分，但是对于测试数据的表现就没有想象的那么好，或者极差，这就是所谓的过拟合问题。在数据集中，过拟合的决策树的错误率比经过简化的决策树的错误率要高。</p><h3 id="2、剪枝原理"><a href="#2、剪枝原理" class="headerlink" title="2、剪枝原理"></a>2、剪枝原理</h3><p>CART算法用的是Cost complexity prune<br>$T(i+1)$总是从$Ti$生成。</p><p><img src="/CART/CART_cut.png" width="800" height="800"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次学习我们将详细介绍什么是CART决策树算法，以及它的前身ID3算法。介绍所涉及到的概念，算法的原理和步骤。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习算法" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>updating</title>
    <link href="http://yoursite.com/updating/"/>
    <id>http://yoursite.com/updating/</id>
    <published>2018-12-19T11:12:00.000Z</published>
    <updated>2018-12-25T11:28:53.047Z</updated>
    
    <content type="html"><![CDATA[<h1 id="我已经努力更新了，过一天再来看看吧，如果着急，就在评论下面催催我，我就马上熬夜为各位赶工！"><a href="#我已经努力更新了，过一天再来看看吧，如果着急，就在评论下面催催我，我就马上熬夜为各位赶工！" class="headerlink" title="我已经努力更新了，过一天再来看看吧，如果着急，就在评论下面催催我，我就马上熬夜为各位赶工！"></a>我已经努力更新了，过一天再来看看吧，如果着急，就在评论下面催催我，我就马上熬夜为各位赶工！</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;我已经努力更新了，过一天再来看看吧，如果着急，就在评论下面催催我，我就马上熬夜为各位赶工！&quot;&gt;&lt;a href=&quot;#我已经努力更新了，过一天再来看看吧，如果着急，就在评论下面催催我，我就马上熬夜为各位赶工！&quot; class=&quot;headerlink&quot; title=&quot;我已
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>数据挖掘实战1-电力窃漏电用户识别</title>
    <link href="http://yoursite.com/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%981-%E7%94%B5%E5%8A%9B%E7%AA%83%E6%BC%8F%E7%94%B5%E7%94%A8%E6%88%B7%E8%AF%86%E5%88%AB/"/>
    <id>http://yoursite.com/数据挖掘实战1-电力窃漏电用户识别/</id>
    <published>2018-12-19T11:12:00.000Z</published>
    <updated>2019-01-05T10:14:12.157Z</updated>
    
    <content type="html"><![CDATA[<p>本次学习我们将使用<a href="https://wltongxue.github.io/%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" target="_blank" rel="noopener">“什么是数据挖掘”</a>中的挖掘过程：根据实际问题定义挖掘目标、取什么样的原始数据、对原始数据的探索分析、如何对数据进行处理、建立合适的模型完成目标、评估模型完成的好不好。<br><a id="more"></a></p><blockquote><p>问题背景：实际生活中，有很多人可能会偷别人的电用，或者计量电量的设备坏了，造成无法根据实际用电情况计价，可能导致用户多交或少交了钱。我们可以使用自动化设备实现对用户用电负荷等数据进行采集，通过从这个数据中找到异常的情况。</p></blockquote><h1 id="一、挖掘目标"><a href="#一、挖掘目标" class="headerlink" title="一、挖掘目标"></a>一、挖掘目标</h1><p>1、归纳出窃漏电用户的关键特征，构建窃漏电用户的识别模型<br>2、利用实时监测数据，调用窃漏电用户识别模型实现实时判断是否是窃漏电用户。<br><strong>根据目标可以知道这类问题属于分类预测问题，根据数据预测这个用户属于哪一类用户，到底是正常用户，还是偷电用户？所以我们后面会考虑用分类和预测的算法模型进行建模。</strong></p><h1 id="二、数据抽取："><a href="#二、数据抽取：" class="headerlink" title="二、数据抽取："></a>二、数据抽取：</h1><p>1、从营销系统抽取用户信息<br>2、从计量自动化系统采集电量、负荷等<br>如下图，你可以看到能实际采集到的数据如下：<br><img src="/数据挖掘实战1-电力窃漏电用户识别/electronic_data.png" width="800" height="800"></p><h1 id="三、数据探索：分布分析-周期性分析"><a href="#三、数据探索：分布分析-周期性分析" class="headerlink" title="三、数据探索：分布分析+周期性分析"></a>三、数据探索：分布分析+周期性分析</h1><p><strong>探索与预测无关的数据，缩小数据集范围，达到精准预测</strong></p><h3 id="1、分布分析"><a href="#1、分布分析" class="headerlink" title="1、分布分析"></a>1、分布分析</h3><p>统计5年内所有窃漏用户进行分布分析，统计出各个用电类别的窃漏电用户分布情况，如下图所示，可以发现非居民类别不存在窃漏电情况，故在接下来的分析中不考虑非居民类别的用电数据。<br><img src="/数据挖掘实战1-电力窃漏电用户识别/user_stoleelectric.png" width="512" height="512"></p><h3 id="2、周期性分析"><a href="#2、周期性分析" class="headerlink" title="2、周期性分析"></a>2、周期性分析</h3><p>随机抽取一个正常用电用户和一个窃漏电用户，周期性对电量进行探索。<br>（1）正常用电，如下图所示，总体来说用电量比较平稳，没有太大的波动。<br><img src="/数据挖掘实战1-电力窃漏电用户识别/normal_user.png" width="512" height="512"><br>（2）窃漏电用户用电量出现明显下降的趋势，如下图所示。<br><img src="/数据挖掘实战1-电力窃漏电用户识别/bad_user.png" width="512" height="512"></p><blockquote><p>分析结论：窃漏电的过程就是用电量持续下降的过程。</p></blockquote><h1 id="四、数据预处理"><a href="#四、数据预处理" class="headerlink" title="四、数据预处理"></a>四、数据预处理</h1><p>数据本身的样子可能并不适合我们处理，比如跟预测结论没有关系的数据，我们可以过滤掉。比如存在一些缺失值，样本很多的情况下我们就大方的删了，但样本很少的时候，我们就需要把它补上。比如好多个数据之间有明显的关系，我们可以把他们合并为一个数据作为特征明显指标。总之，我们对于数据的预处理目的就是：<strong>用尽可能少的数据探索出尽可能精准的结果。</strong><br>1、缺失值可以删除也可以插补，插补的方法很多，我们这里使用“拉格朗日插值法”进行数据的补充,（该数学推导请<a href="https://wltongxue.github.io/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E6%8F%92%E5%80%BC%E6%B3%95/" target="_blank" rel="noopener">点击这里</a>查看）。<br>我们这里调用python库中已经实现的拉格朗日函数对样本数据进行插值，代码如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*-coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#拉格朗日插值代码</span></span><br><span class="line">import pandas as pd <span class="comment">#导入数据分析库</span></span><br><span class="line">from scipy.interpolate import lagrange <span class="comment">#导入拉格朗日函数</span></span><br><span class="line"></span><br><span class="line">inputfile = <span class="string">'../data/missing_data.xls'</span><span class="comment">#输入数据路径，需要使用ecel格式</span></span><br><span class="line">outputfile= <span class="string">'../tmp/missing_data_processed.xls'</span> <span class="comment">#输出数据路径，需要使用Excel格式</span></span><br><span class="line"></span><br><span class="line">data=pd.read_excel(inputfile,header=None) <span class="comment">#读入数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自定义列向量插值函数</span></span><br><span class="line"><span class="comment">#s为列向量（表中某个字段的所有数据），n为被插值的位置，k为取前后的数据个数，默认为5</span></span><br><span class="line"><span class="comment">#取总共11个数据构建拉格朗日函数</span></span><br><span class="line">def ployinterp_column(s,n,k=5):</span><br><span class="line">y=s[list(range(n-k,n)) + list(range(n+1,n+1+k))]</span><br><span class="line">y=y[y.notnull()]<span class="comment">#剔除空值</span></span><br><span class="line"><span class="built_in">return</span> lagrange(y.index,list(y))(n) <span class="comment">#插值并返回插值结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#逐个元素判断是否需要插值</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data.columns:</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line"><span class="keyword">if</span>(data[i].isnull())[j]:<span class="comment">#如果为空即插值</span></span><br><span class="line">data[i][j]=ployinterp_column(data[i],j)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出结果</span></span><br><span class="line">data.to_excel(outputfile,header=None,index=False)</span><br></pre></td></tr></table></figure></p><p>如下图，拉格朗日插补法的效果如下：<br><img src="/数据挖掘实战1-电力窃漏电用户识别/largrane_result.png" width="512" height="512"><br>我们就使用这样的方法处理所有的数据，这里就不再赘述，紧接着我们从大量数据中抽取291个专家样本数据（使用这291个数据进行模型构建）。从原始数据开始到现在为止，其实我们已经做了三件事情了：<br><strong>1、过滤掉无关的属性，例如用户编号。<br>2、缺失值处理。<br>3、从大量数据中选取291个样本数据。</strong><br>现在，我们要对291个样本数据进行降维处理（也就是将相关属性合并为一个属性）<br>我们构建三个指标（新属性，由旧属性变换而来）：<br>（1）电量趋势下降指标。对每天的前后5天（总共11天）计算电量的下降趋势（即斜率）<br>（2）线损指标。若第L天的线路供电为S,线路上各个用户用电总量为W,则线损率T=(S-W)/S * 100%<br>（3）告警类指标。计算终端报警的次数总和。<br>这里只展示最终数据，数据变换的过程根据实际意义可以进行修改。最终数据如下，最后一列给定结果是为了模型的学习和模型的评估，最终是为了这个模型可以预测其他的不可知漏电行为。<br><img src="/数据挖掘实战1-电力窃漏电用户识别/model_data.png" width="512" height="512"></p><h1 id="五、模型构建"><a href="#五、模型构建" class="headerlink" title="五、模型构建"></a>五、模型构建</h1><p>我们已经完成的数据的处理，现在的数据可以用来训练和测试模型。<br><strong>重点来了，由于我们是分类问题，所以我们从分类模型中选择模型。这里实际上是一个二分类问题，结果只有0或者1，此时我们就不会选择回归分析（因为回归分析是分析连续性结果）；并且我们的属性并不多，所以我们会更倾向选择决策树算法或者神经网络算法。这里在决策树算法中选择CART算法（算法详解请<a href="https://wltongxue.github.io/CART/" target="_blank" rel="noopener">点击这里</a>），在神经网络算法中选择LM算法（算法详解请<a href="https://wltongxue.github.io/LM-BP/" target="_blank" rel="noopener">点击这里</a>）。实际上其他一些算法也能应用于该问题，感兴趣的读者也可以尝试效果，我们在这里只选择两个常见的进行比较。</strong><br>我们的整体过程如下图，<br><img src="/数据挖掘实战1-电力窃漏电用户识别/build_model.png" width="512" height="512"><br>这里稍微简单的说一下机器学习的过程，首先切分数据集为训练集和测试集（也可以是独立的两个数据集），然后我们选择合适的算法，每种算法模型都可以有多种参数，但是确定什么样的参数才能解决我们当前的问题，这就需要训练集一个一个的带入到算法模型里然后一步一步的调整到合适的参数获得模型。最后我们需要把测试集代入到训练好的模型里，评估一下这个模型是不是在任何该问题的数据下都能够准确的得到预测结果。评估分类模型的指标也有很多（参考<a href="https://wltongxue.github.io/%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" target="_blank" rel="noopener">什么是数据挖掘</a>）,本章我们选择ROC曲线（<a href="https://wltongxue.github.io/ROC/" target="_blank" rel="noopener">什么是ROC曲线</a>）。</p><h3 id="按照上图的步骤我们进行代码的编写："><a href="#按照上图的步骤我们进行代码的编写：" class="headerlink" title="按照上图的步骤我们进行代码的编写："></a>按照上图的步骤我们进行代码的编写：</h3><p>1、数据划分代码：<br>导入291个样本，将数据分为训练集和测试集<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd <span class="comment">#导入数据分析库</span></span><br><span class="line">from random import shuffle <span class="comment">#导入随机函数shuffle,用来打乱数据</span></span><br><span class="line"></span><br><span class="line">datafile=<span class="string">'../data/model.xls'</span> <span class="comment">#数据名</span></span><br><span class="line">data=pd.read_excel(datafile) <span class="comment">#读取数据，数据的前三列是特征，第四列是标签</span></span><br><span class="line">data=data.as_matrix() <span class="comment">#将表格转换为矩阵</span></span><br><span class="line">shuffle(data) <span class="comment">#随机打乱数据</span></span><br><span class="line"></span><br><span class="line">p = 0.8 <span class="comment">#设置训练数据比例</span></span><br><span class="line">train=data[:int(len(data)*p),:]<span class="comment">#前80%为训练集</span></span><br><span class="line"><span class="built_in">test</span>=data[int(len(data)*p):,:]<span class="comment">#后20%为测试集</span></span><br></pre></td></tr></table></figure></p><p>2、LM神经网络算法：<br>这里用到了python的神经网络库keras，构建三层网络模型，训练模型并且保存模型。这里的ROC曲线代码在评估阶段提供<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########构建LM神经网络模型##########</span></span><br><span class="line">from keras.models import Sequential <span class="comment">#导入神经网络初始化函数</span></span><br><span class="line">from keras.layers.core import Dense,Activation <span class="comment">#导入神经网络层函数、激活函数</span></span><br><span class="line">from keras.models import load_model</span><br><span class="line"></span><br><span class="line">netfile=<span class="string">'../tmp/net.model'</span> <span class="comment">#构建的神经网络模型存储路径</span></span><br><span class="line"></span><br><span class="line">net = Sequential() <span class="comment">#简历神经网络</span></span><br><span class="line">net.add(Dense(input_dim=3,output_dim=10)) <span class="comment">#添加输入层（3节点）到隐藏层（10节点）的连接</span></span><br><span class="line">net.add(Activation(<span class="string">'relu'</span>)) <span class="comment">#隐藏层使用relu激活函数</span></span><br><span class="line">net.add(Dense(input_dim=10,output_dim=1)) <span class="comment">#添加隐藏层（10节点）到输出层（1节点）的连接</span></span><br><span class="line">net.add(Activation(<span class="string">"sigmoid"</span>))<span class="comment">#输出层使用sigmoid激活函数</span></span><br><span class="line"><span class="comment">#导入训练好的model_weights</span></span><br><span class="line"><span class="comment">#net.load_weights(netfile)</span></span><br><span class="line"><span class="comment">#编译模型，使用adam方法求解</span></span><br><span class="line">net.compile(loss=<span class="string">'binary_crossentropy'</span>,optimizer=<span class="string">'adam'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#:3标识前3列（因为第四列是标签）</span></span><br><span class="line">net.fit(train[:,:3],train[:,3],nb_epoch=1000,batch_size=1)<span class="comment">#训练模型，循环1000次</span></span><br><span class="line">net.save_weights(netfile) <span class="comment">#保存模型</span></span><br><span class="line">predict_result = net.predict_classes(train[:,:3]).reshape(len(train))<span class="comment">#预测结果变形</span></span><br><span class="line"><span class="string">''</span><span class="string">'这里要提醒的是，keras用predict给出预测概率，predict_class才是给出预测类别，</span></span><br><span class="line"><span class="string">    而且两者的预测结果都是n x 1维数组，而不是通常的1 下n'</span><span class="string">''</span></span><br><span class="line"></span><br><span class="line">from cm_plot import * <span class="comment">#导入自行编写的混淆矩阵可视化函数（）</span></span><br><span class="line">cm_plot(train[:,3],predict_result).show() <span class="comment">#显示混淆矩阵可视化结果</span></span><br><span class="line"><span class="comment">#显示ROC曲线</span></span><br><span class="line">predict_result_test=net.predict(<span class="built_in">test</span>[:,:3]).reshape(len(<span class="built_in">test</span>)) <span class="comment">#预测结果变形</span></span><br><span class="line">roc_plot(<span class="built_in">test</span>[:,3],predict_result_test ,<span class="string">'ROC of LM'</span>)</span><br></pre></td></tr></table></figure></p><p>3、CART决策树<br>这里使用python的sklearn库<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构建CART决策树模型</span></span><br><span class="line">from sklearn.tree import DecisionTreeClassifier <span class="comment">#导入决策树模型</span></span><br><span class="line"></span><br><span class="line">treefile=<span class="string">'../tmp/tree.pk1'</span><span class="comment">#模型输出名字</span></span><br><span class="line">tree = DecisionTreeClassifier() <span class="comment">#建立决策树模型</span></span><br><span class="line">tree.fit(train[:,:3],train[:,3]) <span class="comment">#训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#保存模型</span></span><br><span class="line">from sklearn.externals import joblib</span><br><span class="line">joblib.dump(tree,treefile)</span><br><span class="line"></span><br><span class="line">from cm_plot import * <span class="comment">#导入画混淆矩阵和ROC曲线的模块（自定义模块）</span></span><br><span class="line">cm_plot(train[:,3],tree.predict(train[:,:3])).show() <span class="comment">#显示混淆矩阵</span></span><br><span class="line"><span class="comment">#注意到Scikit-Learn使用predict方法直接给出预测结果</span></span><br><span class="line"><span class="comment">#显示roc曲线</span></span><br><span class="line">roc_plot(<span class="built_in">test</span>[:,3],tree.predict_proba(<span class="built_in">test</span>[:,:3])[:,1],<span class="string">'ROC of CART'</span>)</span><br></pre></td></tr></table></figure></p><p>4、ROC曲线<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt <span class="comment">#包含画图工具</span></span><br><span class="line"></span><br><span class="line"><span class="string">''</span><span class="string">'画混淆矩阵图'</span><span class="string">''</span></span><br><span class="line">def cm_plot(y, yp):</span><br><span class="line">  </span><br><span class="line">  from sklearn.metrics import confusion_matrix <span class="comment">#导入混淆矩阵函数</span></span><br><span class="line">  cm = confusion_matrix(y, yp) <span class="comment">#混淆矩阵</span></span><br><span class="line"></span><br><span class="line">  plt.matshow(cm, cmap=plt.cm.Greens) <span class="comment">#画混淆矩阵图，配色风格使用cm.Greens，更多风格请参考官网。</span></span><br><span class="line">  plt.colorbar() <span class="comment">#颜色标签</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> x <span class="keyword">in</span> range(len(cm)): <span class="comment">#数据标签</span></span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(len(cm)):</span><br><span class="line">      plt.annotate(cm[x,y], xy=(x, y), horizontalalignment=<span class="string">'center'</span>, verticalalignment=<span class="string">'center'</span>)</span><br><span class="line">  </span><br><span class="line">  plt.ylabel(<span class="string">'True label'</span>) <span class="comment">#坐标轴标签</span></span><br><span class="line">  plt.xlabel(<span class="string">'Predicted label'</span>) <span class="comment">#坐标轴标签</span></span><br><span class="line">  <span class="built_in">return</span> plt</span><br><span class="line"></span><br><span class="line"><span class="string">''</span><span class="string">'画ROC曲线图'</span><span class="string">''</span></span><br><span class="line"><span class="comment">#绘制决策树模型的ROC曲线</span></span><br><span class="line">from sklearn.metrics import roc_curve <span class="comment">#导入ROC曲线函数</span></span><br><span class="line">def roc_plot(x,xp,l):</span><br><span class="line">    fpr,tpr,thresholds=roc_curve(x,xp,</span><br><span class="line">                             pos_label=1)</span><br><span class="line">    plt.plot(fpr,tpr,linewidth=2,label=l) <span class="comment">#做出ROC曲线</span></span><br><span class="line">    plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">    plt.ylim(0,1.05)<span class="comment">#边界范围</span></span><br><span class="line">    plt.xlim(0,1.05)<span class="comment">#边界范围</span></span><br><span class="line">    plt.legend(loc=4)<span class="comment">#图列</span></span><br><span class="line">    plt.show() <span class="comment">#显示作图结果</span></span><br><span class="line">    <span class="built_in">return</span> plt</span><br></pre></td></tr></table></figure></p><p>在这里补充一下，每一次随机分的训练集和测试集并不完全相同，代码运行一次，分一次数据集，就不一样一次，所以每一次的训练得出的模型并不是完全相同的，但我们希望比较两个算法的优缺点时，我们希望他们要用同一个训练集，同一个测试集，所以这里补充一下，把两个算法写在一起训练并且比较ROC曲线更有说服力。（ps:上面的训练集划分和两个算法的代码可以等同于如下：）<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line">import sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'ISO-8859-1'</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">''</span><span class="string">'读取数据，设置数据'</span><span class="string">''</span></span><br><span class="line">import pandas as pd <span class="comment">#导入数据分析库</span></span><br><span class="line">from random import shuffle <span class="comment">#导入随机函数shuffle,用来打乱数据</span></span><br><span class="line"></span><br><span class="line">datafile=<span class="string">'../data/model.xls'</span> <span class="comment">#数据名</span></span><br><span class="line">data=pd.read_excel(datafile) <span class="comment">#读取数据，数据的前三列是特征，第四列是标签</span></span><br><span class="line">data=data.as_matrix() <span class="comment">#将表格转换为矩阵</span></span><br><span class="line">shuffle(data) <span class="comment">#随机打乱数据</span></span><br><span class="line"></span><br><span class="line">p = 0.8 <span class="comment">#设置训练数据比例</span></span><br><span class="line">train=data[:int(len(data)*p),:]<span class="comment">#前80%为训练集</span></span><br><span class="line"><span class="built_in">test</span>=data[int(len(data)*p):,:]<span class="comment">#后20%为测试集</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#让LM和CART使用同一个数据分法进行比较</span></span><br><span class="line"></span><br><span class="line"><span class="string">''</span><span class="string">'LM预测'</span><span class="string">''</span></span><br><span class="line"><span class="comment">#########构建LM神经网络模型##########</span></span><br><span class="line">from keras.models import Sequential <span class="comment">#导入神经网络初始化函数</span></span><br><span class="line">from keras.layers.core import Dense,Activation <span class="comment">#导入神经网络层函数、激活函数</span></span><br><span class="line">from keras.models import load_model</span><br><span class="line"></span><br><span class="line">netfile=<span class="string">'../tmp/net.model'</span> <span class="comment">#构建的神经网络模型存储路径</span></span><br><span class="line"></span><br><span class="line">net = Sequential() <span class="comment">#简历神经网络</span></span><br><span class="line">net.add(Dense(input_dim=3,output_dim=10)) <span class="comment">#添加输入层（3节点）到隐藏层（10节点）的连接</span></span><br><span class="line">net.add(Activation(<span class="string">'relu'</span>)) <span class="comment">#隐藏层使用relu激活函数</span></span><br><span class="line">net.add(Dense(input_dim=10,output_dim=1)) <span class="comment">#添加隐藏层（10节点）到输出层（1节点）的连接</span></span><br><span class="line">net.add(Activation(<span class="string">"sigmoid"</span>))<span class="comment">#输出层使用sigmoid激活函数</span></span><br><span class="line"><span class="comment">#编译模型，使用adam方法求解</span></span><br><span class="line">net.compile(loss=<span class="string">'binary_crossentropy'</span>,optimizer=<span class="string">'adam'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#:3标识前3列（因为第四列是标签）</span></span><br><span class="line">net.fit(train[:,:3],train[:,3],nb_epoch=1000,batch_size=1)<span class="comment">#训练模型，循环1000次</span></span><br><span class="line">net.save_weights(netfile) <span class="comment">#保存模型</span></span><br><span class="line"></span><br><span class="line">predict_result = net.predict_classes(train[:,:3]).reshape(len(train))<span class="comment">#预测结果变形</span></span><br><span class="line"><span class="string">''</span><span class="string">'这里要提醒的是，keras用predict给出预测概率，predict_class才是给出预测类别，</span></span><br><span class="line"><span class="string">    而且两者的预测结果都是n x 1维数组，而不是通常的1 下n'</span><span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="string">''</span><span class="string">'CART预测'</span><span class="string">''</span></span><br><span class="line"><span class="comment">#构建CART决策树模型</span></span><br><span class="line">from sklearn.tree import DecisionTreeClassifier <span class="comment">#导入决策树模型</span></span><br><span class="line">tree = DecisionTreeClassifier() <span class="comment">#建立决策树模型</span></span><br><span class="line">tree.fit(train[:,:3],train[:,3]) <span class="comment">#训练</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">''</span><span class="string">'画混淆矩阵和ROC曲线'</span><span class="string">''</span></span><br><span class="line">from cm_plot import * <span class="comment">#导入自行编写的混淆矩阵可视化函数（）</span></span><br><span class="line">cm_plot(train[:,3],predict_result).show() <span class="comment">#显示混淆矩阵可视化结果</span></span><br><span class="line">cm_plot(train[:,3],tree.predict(train[:,:3])).show() <span class="comment">#显示混淆矩阵</span></span><br><span class="line"><span class="comment">#显示ROC曲线</span></span><br><span class="line">predict_result_test=net.predict(<span class="built_in">test</span>[:,:3]).reshape(len(<span class="built_in">test</span>)) <span class="comment">#预测结果变形</span></span><br><span class="line">roc_plot(<span class="built_in">test</span>[:,3],predict_result_test ,<span class="string">'ROC of LM'</span>)</span><br><span class="line">roc_plot(<span class="built_in">test</span>[:,3],tree.predict_proba(<span class="built_in">test</span>[:,:3])[:,1],<span class="string">'ROC of CART'</span>)</span><br></pre></td></tr></table></figure></p><h1 id="六、模型评价"><a href="#六、模型评价" class="headerlink" title="六、模型评价"></a>六、模型评价</h1><p>根据上述两个算法同时比较的代码，可得到如下ROC曲线：<br><img src="/数据挖掘实战1-电力窃漏电用户识别/roc.png" width="512" height="512"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次学习我们将使用&lt;a href=&quot;https://wltongxue.github.io/%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;“什么是数据挖掘”&lt;/a&gt;中的挖掘过程：根据实际问题定义挖掘目标、取什么样的原始数据、对原始数据的探索分析、如何对数据进行处理、建立合适的模型完成目标、评估模型完成的好不好。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="数据挖掘实战讲解系列" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%E8%AE%B2%E8%A7%A3%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="分类预测问题" scheme="http://yoursite.com/tags/%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>什么是数据挖掘</title>
    <link href="http://yoursite.com/%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    <id>http://yoursite.com/什么是数据挖掘/</id>
    <published>2018-12-10T11:27:57.000Z</published>
    <updated>2019-01-05T09:08:06.333Z</updated>
    
    <content type="html"><![CDATA[<p>整个系列实战源码下载地址：<a href="https://github.com/wltongxue/python-DataMining-Practice" target="_blank" rel="noopener">https://github.com/wltongxue/python-DataMining-Practice</a><br>本次学习我们将从4个方面进行深入介绍：<br><strong>1、数据挖掘的定义。</strong>（了解什么是数据挖掘？它是用来干什么的？）<br><strong>2、数据挖掘的过程。</strong>（明白数据挖掘要做什么事情？）<br><strong>3、挖掘建模中的算法和评价。</strong>（了解挖掘中最重要的建模部分都有哪些？）<br><strong>4、所使用的python库。</strong>（使用代码进行实现时我们要具备的环境？）<br><a id="more"></a></p><h1 id="一、什么是数据挖掘"><a href="#一、什么是数据挖掘" class="headerlink" title="一、什么是数据挖掘"></a>一、什么是数据挖掘</h1><p>1、数据挖掘一般是指从大量的数据中通过<strong>算法搜索</strong>隐藏于其中信息的过程。（这里如果不懂，可以先往下看，会举例说明）<br>2、基本任务包括<strong>利用分类与预测、聚类分析、关联规则、时序模式、偏差检测、智能推荐等方法</strong>，从数据中提取蕴含价值的信息。<br>3、根据<strong>问题决定属于哪一类任务</strong>，确定任务以后再决定使用什么算法建模<br><em>注：机器学习算法指的是分类与预测 和 聚类分析算法（每一次从数据集的学习都是不确定的，这样的算法叫做机器学习算法）</em></p><h1 id="二、数据挖掘的过程"><a href="#二、数据挖掘的过程" class="headerlink" title="二、数据挖掘的过程"></a>二、数据挖掘的过程</h1><p>&#160; &#160;数据挖掘的过程及描述：</p><style>table th:first-of-type {    width: 100px;}</style><table><thead><tr><th>过程</th><th>描述</th></tr></thead><tbody><tr><td>定义挖掘目标</td><td>要实现什么样的功能，找到什么样的信息</td></tr><tr><td>数据取样</td><td>需要哪些原始的数据</td></tr><tr><td>数据探索</td><td>对数据进行了解分析（直观或统计）、数据质量分析（脏数据等）、数据特征分析（分布等）</td></tr><tr><td>数据预处理</td><td>数据清洗、数据集成、数据变换、数据规约；降维、补缺等修剪来获得“好”数据</td></tr><tr><td>挖掘建模</td><td>首先判断属于哪类问题（分类、聚类等）；选用对应的算法和模型进行数据分析</td></tr><tr><td>模型评估</td><td>对所选用的模型进行评测；利用该类模型的评估指标（方差、ROC等）</td></tr></tbody></table><p><em>注：数据探索和数据预处理都是为了获取到好的数据训练而服务的<br>&#160; &#160;脏数据包括：缺失、异常、一致<br>&#160; &#160;特征分析：分布、对比、统计量、周期性、贡献度、相关性<br>&#160; &#160;统计数据清洗：缺失值、异常值处理<br>&#160; &#160;数据集成：实体识别、冗余属性识别<br>&#160; &#160;数据变换：简单函数变换、规范化、连续属性离散化、属性构造、小波变换<br>&#160; &#160;数据规约：属性规约、数值规约 </em></p><h1 id="三、挖掘建模中常用的算法和评价"><a href="#三、挖掘建模中常用的算法和评价" class="headerlink" title="三、挖掘建模中常用的算法和评价"></a>三、挖掘建模中常用的算法和评价</h1><p>&#160; &#160;机器学习算法指的是<strong>分类与预测和聚类分析算法（每一次从数据集的学习都是不确定的）</strong>，并且模型在不断学习提升（变化），所以机器学习获得的模型或者算法是需要评价，评价学习结果的好坏。</p><h3 id="1、分类与预测"><a href="#1、分类与预测" class="headerlink" title="1、分类与预测"></a>1、分类与预测</h3><h4 id="分类与预测常用算法"><a href="#分类与预测常用算法" class="headerlink" title="分类与预测常用算法"></a>分类与预测常用算法</h4><p>解决的问题：预测分类标号、预测某个值<br>1、回归分析：线性、非线性、Logistic、岭回归、主成分<br>2、决策树：ID3、C4.5、CART<br>3、人工神经网络：BP、LM、RBF、FNN、GMDH、ANFIS<br>4、贝叶斯网络<br>5、支持向量机（SVM）</p><h4 id="分类与预测算法评价指标"><a href="#分类与预测算法评价指标" class="headerlink" title="分类与预测算法评价指标"></a>分类与预测算法评价指标</h4><p>1、绝对误差与相对误差<br>2、平均绝对误差<br>3、均方误差<br>4、均方根误差<br>5、平均绝对百分误差<br>6、Kappa统计<br>7、识别准确度<br>8、识别精确率<br>9、反馈率<br>10、ROC曲线<br>11、混淆矩阵</p><h3 id="2、聚类分析"><a href="#2、聚类分析" class="headerlink" title="2、聚类分析"></a>2、聚类分析</h3><h4 id="聚类分析常用算法"><a href="#聚类分析常用算法" class="headerlink" title="聚类分析常用算法"></a>聚类分析常用算法</h4><p>解决的问题：非监督、无类标记、自行分类<br>1、K-means<br>2、K-中心点<br>3、系统聚类</p><h4 id="聚类分析算法评价"><a href="#聚类分析算法评价" class="headerlink" title="聚类分析算法评价"></a>聚类分析算法评价</h4><p>1、purity评价法<br>2、R1评价法<br>3、F值评价法</p><h3 id="3、关联规则"><a href="#3、关联规则" class="headerlink" title="3、关联规则"></a>3、关联规则</h3><h4 id="关联规则的常用算法"><a href="#关联规则的常用算法" class="headerlink" title="关联规则的常用算法"></a>关联规则的常用算法</h4><p>解决的问题：找出数据之间的关系<br>1、Apriori<br>2、FP-Tree<br>3、Eclat算法<br>4、灰色关联法</p><h3 id="4、时序模式"><a href="#4、时序模式" class="headerlink" title="4、时序模式"></a>4、时序模式</h3><h4 id="时序模式常用时序模型"><a href="#时序模式常用时序模型" class="headerlink" title="时序模式常用时序模型"></a>时序模式常用时序模型</h4><p>解决的问题：给定时间序列、预测未来值<br>1、平滑法、趋势拟合法、组合模型<br>2、AR模型、MA模型、ARMA模型、ARIMA模型<br>3、ARCH模型、GARCH模型</p><h3 id="5、离群点检测"><a href="#5、离群点检测" class="headerlink" title="5、离群点检测"></a>5、离群点检测</h3><h4 id="离群点检测方法"><a href="#离群点检测方法" class="headerlink" title="离群点检测方法"></a>离群点检测方法</h4><p>解决的问题：发现信息的噪声点<br>1、基于统计的<br>2、基于邻近度的<br>3、基于密度的<br>4、基于聚类的</p><h1 id="四、所使用的python库"><a href="#四、所使用的python库" class="headerlink" title="四、所使用的python库"></a>四、所使用的python库</h1><p>&#160; &#160;Python数据挖掘相关扩展库：</p><style>table th:first-of-type {    width: 100px;}</style><table><thead><tr><th>扩展库</th><th>描述</th></tr></thead><tbody><tr><td>Numpy</td><td>提供数组支持，以及相应的高效的处理函数</td></tr><tr><td>Scipy</td><td>提供矩阵支持，以及矩阵相关的数值计算模块</td></tr><tr><td>Matplotlib</td><td>强大的数据可视化工具、作图库</td></tr><tr><td>Pandas</td><td>强大、灵活的数据分析和探索工具</td></tr><tr><td>StatsModels</td><td>统计建模和计量经济学，包括描述统计、统计模型估计和推断</td></tr><tr><td>Scikit-Learn</td><td>支持回归、分析、聚类等的强大的机器学习库</td></tr><tr><td>Keras</td><td>深度学习库，用于建立神经网络以及深度学习模型</td></tr><tr><td>Genism</td><td>用来做文本主题模型的库，本文挖掘可能用到</td></tr></tbody></table><h1 id="五、实践展示"><a href="#五、实践展示" class="headerlink" title="五、实践展示"></a>五、实践展示</h1><ul><li><a href="https://wltongxue.github.io/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%981-%E7%94%B5%E5%8A%9B%E7%AA%83%E6%BC%8F%E7%94%B5%E7%94%A8%E6%88%B7%E8%AF%86%E5%88%AB/" target="_blank" rel="noopener">电力窃漏电用户自动识别</a></li><li>航空公司客户价值分析</li><li>中医证型关联规则挖掘</li><li>基于水色图像的水质评价</li><li>家用电器用户行为分析与事件识别</li><li>应用系统负载分析与磁盘容量预测</li><li>电子商务网站用户行为分析及服务推荐</li><li>财政收入影响因素分析及预测模型</li><li>基于基站定位数据的商圈分析</li><li>电商产品评论数据情感分析</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;整个系列实战源码下载地址：&lt;a href=&quot;https://github.com/wltongxue/python-DataMining-Practice&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/wltongxue/python-DataMining-Practice&lt;/a&gt;&lt;br&gt;本次学习我们将从4个方面进行深入介绍：&lt;br&gt;&lt;strong&gt;1、数据挖掘的定义。&lt;/strong&gt;（了解什么是数据挖掘？它是用来干什么的？）&lt;br&gt;&lt;strong&gt;2、数据挖掘的过程。&lt;/strong&gt;（明白数据挖掘要做什么事情？）&lt;br&gt;&lt;strong&gt;3、挖掘建模中的算法和评价。&lt;/strong&gt;（了解挖掘中最重要的建模部分都有哪些？）&lt;br&gt;&lt;strong&gt;4、所使用的python库。&lt;/strong&gt;（使用代码进行实现时我们要具备的环境？）&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="数据挖掘实战讲解系列" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%E8%AE%B2%E8%A7%A3%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>拉格朗日插值法</title>
    <link href="http://yoursite.com/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E6%8F%92%E5%80%BC%E6%B3%95/"/>
    <id>http://yoursite.com/拉格朗日插值法/</id>
    <published>2018-12-10T11:27:57.000Z</published>
    <updated>2019-01-02T10:56:17.113Z</updated>
    
    <content type="html"><![CDATA[<p>本次学习我们主要是从数学角度推导一下拉格朗日插值法和牛顿插值法，使读者能更深入理解该数据处理方法。<br><a id="more"></a></p><h1 id="一、拉格朗日插值法"><a href="#一、拉格朗日插值法" class="headerlink" title="一、拉格朗日插值法"></a>一、拉格朗日插值法</h1><p>1）根据数学知识我们知道，对于平面上已知的n个点，可以找到一个n-1次多项式$y=a_0+a_1x+a_2x^2+…+a_{n-1}x^{n-1}$，使此多项式曲线过这n个点。<br>求已知的过n个点的n-1次多项式：<br>$$y=a_0+a_1x+a_2x^2+…+a_{n-1}x^{n-1}$$<br>将n个点的坐标$(x_1,y_1),(x_2,y_2)…(x_n,y_n)$代入多项式函数，得：<br>$$y_1=a_0+a_1x_1+a_2{x_1}^2+…+a_{n-1}{x_1}^{n-1}$$<br>$$y_2=a_0+a_1x_2+a_2{x_2}^2+…+a_{n-1}{x_2}^{n-1}$$<br>$$…$$<br>$$y_n=a_0+a_1x_n+a_2{x_n}^2+…+a_{n-1}{x_n}^{n-1}$$<br>2）于是，我们构造一个函数，这个函数要满足可以取到任意$(x_i,y_i)$这个点<br>$$L(x)=y_1{\frac{(x-x_2)(x-x_3)…(x-x_n)}{(x_1-x_2)(x_1-x_3)…(x_1-x_n)}}<br>        +y_2{\frac{(x-x_1)(x-x_3)…(x-x_n)}{(x_2-x_1)(x_2-x_3)…(x_2-x_n)}}+…<br>        +y_n{\frac{(x-x_1)(x-x_2)…(x-x_{n-1})}{(x_n-x_1)(x_n-x_2)…(x_n-x_{n-1})}}<br>        =\sum_{i=0}^n{y_i{\prod_{j=0,j{\neq}i}^n{\frac{x-x_j}{x_i-x_j}}}}$$<br>令$l(i)={\prod_{j=0,j{\neq}i}^n{\frac{x-x_j}{x_i-x_j}}}$<br>由上式可以发现，$l(i)$只有在$x_i$处取到值1，在$x_j(j{\neq}i)$处都为0，那么$L(x)$这个多项式就可以取到点$(x_i,y_i)$且不影响其他n个点，用无数多个点就可以确定一个线，成为一个连续得函数，就可以求出上式求出某个给定$x$得近似值$L(x)$</p><p><strong>此时提出一个问题：当插值点增减，多项式里的每一项都要变，这很不方便！！<br>所以提出：牛顿插值法</strong></p><h1 id="二、牛顿插值法"><a href="#二、牛顿插值法" class="headerlink" title="二、牛顿插值法"></a>二、牛顿插值法</h1><p>1）差商的定义：<br>函数$f(x)$在两个互异点$x_i,x_j$处的一阶差商定义为：<br>$$f[x_i,x_j]=\frac{f(x_i)-f(x_j)}{x_i-x_j} (i{\neq}j,x_i{\neq}x_j)$$<br>2阶差商：<br>$$f[x_i,x_j,x_k]=\frac{f[x_i,x_j]-f[x_j,x_k]}{x_i-x_k} (i{\neq}k)$$<br>k+1阶差商<br>$$f[x_0,…,x_(k+1)]=\frac{f[x_0,x_1,…,x_k]-f[x_1,…,x_k,x_(k+1)]}{x_0-x_(k+1)}$$<br>2）求已知n个点对$(x_1,y_1),(x_2,y_2),…,(x_n,y_n)$的所有阶差商公式，推导以上$f(x)$:<br><img src="/拉格朗日插值法/newton_f(x)1.png" width="800" height="800"><br><img src="/拉格朗日插值法/newton_f(x)2.png" width="800" height="800"><br>N(x)是逼近函数，R(x)是误差函数<br>3）牛顿插值法的优点：<br>当增加一个插值节点只需在最后加一项，前面各项均不变。<br>也是多项式，取$(x_i,y_i)$不影响其他点，两者结果一样，只是表现形式不同。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次学习我们主要是从数学角度推导一下拉格朗日插值法和牛顿插值法，使读者能更深入理解该数据处理方法。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="基础概念" scheme="http://yoursite.com/categories/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
    
      <category term="数据挖掘" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="数据处理" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
      <category term="插值" scheme="http://yoursite.com/tags/%E6%8F%92%E5%80%BC/"/>
    
  </entry>
  
  <entry>
    <title>爬虫介绍</title>
    <link href="http://yoursite.com/%E7%88%AC%E8%99%AB%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/爬虫介绍/</id>
    <published>2018-11-27T08:49:23.894Z</published>
    <updated>2018-12-20T12:31:42.361Z</updated>
    
    <content type="html"><![CDATA[<p>本章将介绍如何不通过浏览器的帮助来获取、格式化、理解数据。<br><a id="more"></a><br><strong>这里使用的是python3</strong></p><h2 id="网络连接"><a href="#网络连接" class="headerlink" title="网络连接"></a>网络连接</h2><p>通过python请求页面，获取页面代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from urllib.request import url open</span><br><span class="line">html=urlopen(<span class="string">"http://pythonscraping.com"</span>/pages/page1.html)</span><br><span class="line"><span class="built_in">print</span>(html.read())</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本章将介绍如何不通过浏览器的帮助来获取、格式化、理解数据。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="数据采集" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="爬虫" scheme="http://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>How to use Hexo</title>
    <link href="http://yoursite.com/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hexo/"/>
    <id>http://yoursite.com/如何使用hexo/</id>
    <published>2018-11-19T11:39:18.682Z</published>
    <updated>2018-12-20T12:31:49.857Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.<br><a id="more"></a></p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Hexo" scheme="http://yoursite.com/categories/Hexo/"/>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
</feed>
